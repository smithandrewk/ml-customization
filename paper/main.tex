\documentclass[twocolumn]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{float}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}

% Title and authors - TODO: Finalize based on results
\title{Few-Shot Personalization of Wearable Health Monitoring Systems}

\author{
    % TODO: Add author names and affiliations
    Anonymous Author\\
    Anonymous Institution\\
    \texttt{anonymous@email.com}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
% TODO: Write abstract after results are complete
% Target: 150-200 words covering:
% - Motivation: Company deployment scenario
% - Methods: Two-phase LOPO evaluation  
% - Results: Key quantitative findings
% - Impact: Practical deployment insights

\textbf{[TODO: Complete after main results]}
Individual variability in physiological responses presents a significant challenge for deploying wearable health monitoring systems at scale. While companies collect extensive baseline data during initial deployments, the effectiveness of personalizing models using limited target participant data remains unclear. We present a systematic evaluation framework using Leave-One-Participant-Out (LOPO) cross-validation to assess few-shot personalization in smoking detection from accelerometer data. Our two-phase training methodology first learns general patterns from source participants, then adapts to target individuals using minimal data. [RESULTS PLACEHOLDER: Statistical significance, effect sizes, data efficiency findings]. These findings provide practical guidelines for companies implementing personalized health monitoring, demonstrating when and how personalization improves detection accuracy in real-world deployment scenarios.
\end{abstract}

% Keywords for venue submission
\textbf{Keywords:} personalization, health monitoring, few-shot learning, wearables, smoking detection

\section{Introduction}
\label{sec:introduction}

% TODO: Complete introduction section
% Target: ~2 pages covering problem motivation, gaps, contributions

Wearable health monitoring systems have gained widespread adoption in both consumer and clinical settings, with applications ranging from fitness tracking to chronic disease management~\cite{TODO:wearables_review}. However, a fundamental challenge persists: individual physiological and behavioral differences lead to significant variability in sensor data patterns across users~\cite{TODO:individual_variability}. This variability directly impacts the accuracy of automated detection systems when models trained on population data are applied to new individuals.

\subsection{Problem Motivation: Company Deployment Scenario}
Consider a technology company deploying smoking cessation monitoring across a diverse user base. The company has extensive baseline data from initial participants but faces a critical decision: should they use a single population-level model, or invest in personalizing models for each new user? This decision involves trade-offs between deployment complexity, data collection requirements, and potential accuracy improvements.

\subsection{Current Limitations}
% TODO: Expand with relevant citations
Existing personalization approaches in health monitoring suffer from several limitations:
\begin{itemize}
    \item \textbf{Evaluation gaps:} Most studies use within-participant data splits rather than realistic cross-participant evaluation
    \item \textbf{Data requirements:} Unclear minimum target data needed for meaningful improvement
    \item \textbf{Individual variability:} Limited understanding of which participants benefit most from personalization
    \item \textbf{Deployment guidance:} Lack of practical guidelines for real-world implementation
\end{itemize}

\subsection{Our Contributions}
This work addresses these limitations through:
\begin{enumerate}
    \item \textbf{Systematic LOPO Evaluation:} First comprehensive assessment of personalization effectiveness using realistic cross-participant evaluation
    \item \textbf{Data Efficiency Analysis:} Quantification of minimum target data requirements for meaningful improvement
    \item \textbf{Individual Characterization:} Identification of participant factors that predict personalization success
    \item \textbf{Deployment Guidelines:} Practical recommendations for companies implementing personalized health monitoring
\end{enumerate}

% TODO: Add hypothesis statements from research plan
Our key hypotheses include: (H1) Customization will improve F1 scores by >10\% on average, (H2) meaningful improvements are possible with <1 hour of target data, and (H3) base model performance predicts customization success.

\section{Related Work}
\label{sec:related}

% TODO: Complete related work section (~1 page)
% Cover: personalization in health monitoring, few-shot learning, domain adaptation

\subsection{Personalization in Health Monitoring}
% TODO: Add citations and expand
Recent work has explored various approaches to personalizing health monitoring systems~\cite{TODO:health_personalization}. However, most studies focus on within-participant evaluation rather than realistic cross-participant scenarios.

\subsection{Few-Shot Learning and Domain Adaptation}
% TODO: Connect to few-shot learning literature
The challenge of adapting models to new participants with limited data shares similarities with few-shot learning and domain adaptation problems in computer vision and natural language processing~\cite{TODO:few_shot_learning}.

\section{Methods}
\label{sec:methods}

% TODO: Complete methods section (~2 pages)

\subsection{Dataset and Participants}
% TODO: Add specific dataset details after analysis
Our evaluation uses accelerometer data from [X] participants collected during smoking detection studies. Data consists of 50Hz tri-axial accelerometer measurements from wrist-worn devices, with expert-annotated smoking bouts providing ground truth labels.

\textbf{[TODO: Add participant demographics and data statistics]}

\subsection{Two-Phase Training Methodology}
\label{sec:two_phase}

Our approach consists of two distinct training phases designed to mirror real-world company deployment scenarios:

\begin{algorithm}[H]
\caption{Two-Phase Personalization Training}
\label{alg:two_phase}
\begin{algorithmic}[1]
\STATE \textbf{Phase 1: Base Model Training}
\STATE Train CNN model on source participants (all except target)
\STATE Optimize using early stopping on validation F1 score
\STATE Save base model parameters $\theta_{base}$
\STATE
\STATE \textbf{Phase 2: Target Personalization}  
\STATE Initialize model with $\theta_{base}$
\STATE Fine-tune on target participant data
\STATE Apply reduced learning rate and early stopping
\STATE Output personalized model $\theta_{personalized}$
\end{algorithmic}
\end{algorithm}

\subsection{Leave-One-Participant-Out (LOPO) Evaluation}
% TODO: Expand evaluation protocol details
We employ LOPO cross-validation to ensure realistic evaluation conditions that mirror company deployment scenarios. For each target participant:

\begin{enumerate}
    \item Train base model on remaining [X-1] participants
    \item Personalize model using target participant's data
    \item Evaluate on held-out target participant test set
    \item Compare personalized vs. base model performance
\end{enumerate}

\subsection{Model Architecture}
% TODO: Reference SmokingCNN from utils.py
Our smoking detection model uses a 1D convolutional neural network optimized for 60-second accelerometer windows (3000 samples at 50Hz). The architecture employs dilated convolutions to capture long-range temporal dependencies relevant to smoking gesture patterns.

\subsection{Statistical Analysis}
All comparisons use paired statistical tests accounting for participant-level dependencies. We report effect sizes (Cohen's d) with confidence intervals and apply multiple comparison corrections where appropriate.

\section{Results}
\label{sec:results}

% TODO: Complete results section (~3 pages) after experiments

\subsection{Main Findings: Personalization Effectiveness}
\textbf{[TODO: Add Figure 1 - Main Results Bar Chart]}

\textbf{[PLACEHOLDER: Key statistical findings]}
- Base model average F1: [X.XX] ± [X.XX]
- Personalized model average F1: [X.XX] ± [X.XX]  
- Average improvement: [X.XX] ± [X.XX] (p < [X.XXX])
- Effect size (Cohen's d): [X.XX] [95\% CI: X.XX, X.XX]

\subsection{Data Efficiency Analysis}
\textbf{[TODO: Add Figure 2 - Data Efficiency Curves]}

\textbf{[PLACEHOLDER: Data efficiency findings]}
Analysis of personalization effectiveness across different amounts of target data:
- 25\% target data: [X.XX] average improvement
- 50\% target data: [X.XX] average improvement  
- 75\% target data: [X.XX] average improvement
- 100\% target data: [X.XX] average improvement

\subsection{Individual Variability Patterns}
\textbf{[TODO: Add Figure 3 - Individual Analysis]}

\textbf{[PLACEHOLDER: Individual characterization results]}
Factors predicting personalization success:
- Base model performance correlation: r = [X.XX] (p < [X.XXX])
- Data quality metrics correlation: r = [X.XX] (p < [X.XXX])
- Behavioral pattern consistency: [findings]

\subsection{Failure Case Analysis}
\textbf{[PLACEHOLDER: Analysis of negative personalization cases]}
[X] out of [Y] participants showed decreased performance after personalization. Common patterns include:
- Overfitting indicators: [analysis]
- Data insufficiency markers: [analysis]
- Base model ceiling effects: [analysis]

\section{Discussion}
\label{sec:discussion}

% TODO: Complete discussion section (~2 pages)

\subsection{Practical Deployment Guidelines}
Based on our systematic evaluation, we provide the following recommendations for companies implementing personalized health monitoring:

\begin{itemize}
    \item \textbf{When to personalize:} [Evidence-based criteria]
    \item \textbf{Data collection requirements:} [Minimum target data guidelines]
    \item \textbf{Success prediction:} [Participant screening approaches]
    \item \textbf{Implementation strategy:} [Phased deployment recommendations]
\end{itemize}

\subsection{Theoretical Insights}
\textbf{[TODO: Develop theoretical framework]}
Our findings contribute to understanding of personalization in health monitoring by:
- Quantifying individual vs. population-level model trade-offs
- Establishing data efficiency baselines for few-shot health personalization
- Identifying predictive factors for adaptation success

\subsection{Limitations and Future Work}
\textbf{[TODO: Add limitations based on experimental findings]}
Key limitations include:
- Single-task evaluation (smoking detection only)
- Limited participant diversity [expand based on demographics]
- [Other limitations discovered during experiments]

Future work should explore:
- Multi-task personalization across different health behaviors
- Advanced personalization methods beyond fine-tuning
- Longitudinal adaptation as user patterns evolve

\section{Conclusion}
\label{sec:conclusion}

% TODO: Write conclusion after results (~0.5 pages)
\textbf{[PLACEHOLDER: Key takeaways and impact]}

This work provides the first systematic evaluation of few-shot personalization in wearable health monitoring using realistic cross-participant validation. Our findings demonstrate [key results] and provide practical guidelines for companies deploying personalized health monitoring systems. [Impact statement and broader implications].

\section{Acknowledgments}
% TODO: Add appropriate acknowledgments

\bibliographystyle{plain}
\bibliography{references}
% TODO: Create references.bib file

% Appendices for supplementary material
\appendix

\section{Supplementary Methods}
\label{sec:supp_methods}
% TODO: Add implementation details, hyperparameters, reproducibility info

\section{Supplementary Results}  
\label{sec:supp_results}
% TODO: Extended statistical analysis, additional breakdowns

\end{document}