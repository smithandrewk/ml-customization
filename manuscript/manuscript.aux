\relax 
\citation{yang2022jitai}
\citation{leppin2025perspectives}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{}\protected@file@percent }
\newlabel{sec:related_work}{{2}{1}{}{}{}}
\citation{mobile2023interventions}
\citation{ehealth2024systematic}
\citation{smartband2024feasibility}
\citation{ml2023prediction,behavioral2024activation}
\citation{jmir2024sensors}
\citation{senyurek2020cnn}
\citation{abotabik2020smart}
\citation{smoking_realtime_2022}
\citation{wang2022deep,zhang2022deep_har,wang2019deep_HAR}
\citation{kiranyaz2021d}
\citation{1d_cnn_har_2021}
\citation{cnn_lstm_2023,ordóñez2016deep}
\citation{oord2016wavenet,dilated_multivariate_2019}
\citation{dilated_attention_2021}
\citation{dilated_attention_2021}
\citation{gait_analysis_2024}
\citation{student_activity_2024,singh2024hybrid}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Digital Health Interventions for Smoking Cessation}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Smoking Detection Using Wearable Sensors}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deep Learning for Wearable Sensor Data}{2}{}\protected@file@percent }
\citation{chato2023survey}
\citation{pan2010survey,weiss2016survey}
\citation{fu2021personalized}
\citation{liu2024cattle}
\citation{roy2024fewshot}
\citation{shah2023emergence}
\citation{hsieh2023distilling,howard2018universal}
\citation{biomedical_tsc_2022}
\citation{gait_analysis_2024}
\citation{patient_monitoring_2020}
\citation{wpt_health_2024}
\citation{lecun2015deep,goodfellow2016deep,rajpurkar2022ai,esteva2021deep,topol2019high}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Transfer Learning and Personalization in Healthcare}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Time Series Classification for Biomedical Applications}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Positioning of Our Contributions}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{4}{}\protected@file@percent }
\newlabel{sec:methods}{{3}{4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset and Participants}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Architecture}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Data Splits and Evaluation Protocol}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Transfer Learning Strategies}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Data Efficiency Analysis}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Training Methodology}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Evaluation}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Performance Metrics}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Statistical Analysis and Visualization}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{}\protected@file@percent }
\newlabel{sec:results}{{4}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Study design, dataset characteristics, and methodology.} \textbf  {a}, Experimental workflow showing the leave-one-out cross-validation approach for personalization evaluation. Population data from multiple participants is used to train a base model, which is then personalized through fine-tuning on individual target participants' data, followed by evaluation on held-out test data. \textbf  {b}, Dataset characteristics showing the distribution of smoking and non-smoking sessions across all eight participants (P0-P7). Data collection involved accelerometer recordings at 50Hz, with sessions annotated for smoking behavior. \textbf  {c}, Model architecture diagram illustrating the lightweight 1D CNN designed for 60-second accelerometer windows (3000 samples $\times $ 6 features). The network consists of three convolutional layers with increasing filter counts, followed by global average pooling and a binary classifier. \textbf  {d}, Representative accelerometer trace showing characteristic patterns during smoking behavior. The highlighted region demonstrates the distinctive hand-to-mouth gestures captured during smoking events, which the model learns to recognize.}}{7}{}\protected@file@percent }
\newlabel{fig:study_design}{{1}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Personalization significantly improves smoking detection performance across participants.} \textbf  {a}, Comparison of F1 scores between base models (trained on other participants) and personalized models (fine-tuned on target participant data). Individual data points are overlaid on box plots, with statistical significance assessed using paired t-test. Effect size quantified using Cohen's $d$. \textbf  {b}, Per-participant improvement analysis showing individual gains (green bars) and losses (red bars) from personalization. Values represent absolute F1 score improvements. Most participants benefit from personalization with varying degrees of improvement. \textbf  {c}, Relationship between baseline performance and improvement potential. Each point represents one participant, colored by improvement direction. Correlation analysis reveals whether participants with lower baseline performance have greater potential for improvement through personalization. \textbf  {d}, Success rate and effect size summary. Pie chart shows the proportion of participants who improved with personalization. Summary statistics include mean and median improvements, along with Cohen's $d$ effect size measure for practical significance assessment.}}{8}{}\protected@file@percent }
\newlabel{fig:main_results}{{2}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Training dynamics reveal personalization mechanisms and success patterns.} \textbf  {a}, Loss curves aligned by transition epoch showing target validation loss relative to the onset of personalization. Individual participant curves (gray) and population mean with confidence intervals (blue) demonstrate the learning trajectory during personalization. Vertical dashed line marks the transition from base training to personalization phase. \textbf  {b}, Distribution of relative improvement achieved through personalization, calculated as the percentage of remaining performance gap captured: $\frac  {F1_{\text  {personalized}} - F1_{\text  {base}}}{1 - F1_{\text  {base}}} \times 100$. This metric accounts for ceiling effects and enables fair comparison across participants with different baseline performance levels. \textbf  {c}, Convergence analysis examining the relationship between personalization training duration and final improvement. Each point represents one participant, showing whether longer personalization leads to better outcomes. \textbf  {d}, Success pattern analysis categorizing participants by improvement magnitude. Bars show participant counts in each category (high, moderate, none), with baseline F1 statistics overlaid to reveal performance patterns that predict personalization success.}}{9}{}\protected@file@percent }
\newlabel{fig:training_dynamics}{{3}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Transfer learning enables superior performance with limited target data.} Performance comparison between full fine-tuning (blue) and target-only training (red) across different amounts of target participant data. Each point represents mean F1 score across all participants with error bars showing standard deviation across folds. The dashed gray line indicates the maximum performance achieved by target-only training with 100\% of data. Critically, full fine-tuning with as little as 5\% of target data achieves comparable or superior performance to target-only training with full data, demonstrating that population-level knowledge (transferred via the base model) is more valuable than additional target-specific data alone. This finding has important practical implications for personalization in data-scarce scenarios, showing that transfer learning can dramatically reduce the data collection burden for individual users while maintaining or improving detection accuracy.}}{10}{}\protected@file@percent }
\newlabel{fig:data_efficiency}{{4}{10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overall Performance Improvements}{11}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Transfer learning strategy comparison - b128\_aug\_patience50\_full\_fine\_tuning\_pct1.0\_20250929\_144626}}{11}{}\protected@file@percent }
\newlabel{tab:results}{{1}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Detailed Performance Analysis}{11}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Detailed performance metrics - b128\_aug\_patience50\_full\_fine\_tuning\_pct1.0\_20250929\_144626}}{11}{}\protected@file@percent }
\newlabel{tab:detailed_results}{{2}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Individual Variability}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Training Dynamics}{11}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Training dynamics analysis - b128\_aug\_patience50\_full\_fine\_tuning\_pct1.0\_20250929\_144626}}{11}{}\protected@file@percent }
\newlabel{tab:training_dynamics}{{3}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Transfer Learning Data Efficiency}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{12}{}\protected@file@percent }
\newlabel{sec:discussion}{{5}{12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Implications for Practice}{12}{}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{abotabik2020smart}{1}
\bibcite{patient_monitoring_2020}{2}
\bibcite{chato2023survey}{3}
\bibcite{wpt_health_2024}{4}
\bibcite{smartband2024feasibility}{5}
\bibcite{esteva2021deep}{6}
\bibcite{fu2021personalized}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Limitations}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{13}{}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{13}{}{}{}}
\bibcite{goodfellow2016deep}{8}
\bibcite{ml2023prediction}{9}
\bibcite{howard2018universal}{10}
\bibcite{hsieh2023distilling}{11}
\bibcite{smoking_realtime_2022}{12}
\bibcite{biomedical_tsc_2022}{13}
\bibcite{student_activity_2024}{14}
\bibcite{ehealth2024systematic}{15}
\bibcite{kiranyaz2021d}{16}
\bibcite{dilated_multivariate_2019}{17}
\bibcite{lecun2015deep}{18}
\bibcite{leppin2025perspectives}{19}
\bibcite{gait_analysis_2024}{20}
\bibcite{liu2024cattle}{21}
\bibcite{1d_cnn_har_2021}{22}
\bibcite{cnn_lstm_2023}{23}
\bibcite{behavioral2024activation}{24}
\bibcite{oord2016wavenet}{25}
\bibcite{ordóñez2016deep}{26}
\bibcite{pan2010survey}{27}
\bibcite{rajpurkar2022ai}{28}
\bibcite{roy2024fewshot}{29}
\bibcite{senyurek2020cnn}{30}
\bibcite{shah2023emergence}{31}
\bibcite{dilated_attention_2021}{32}
\bibcite{singh2024hybrid}{33}
\bibcite{topol2019high}{34}
\bibcite{wang2019deep_HAR}{35}
\bibcite{wang2022deep}{36}
\bibcite{weiss2016survey}{37}
\bibcite{jmir2024sensors}{38}
\bibcite{yang2022jitai}{39}
\bibcite{zhang2022deep_har}{40}
\bibcite{mobile2023interventions}{41}
\@writefile{toc}{\contentsline {section}{\numberline {A}Model Architecture Details}{16}{}\protected@file@percent }
\newlabel{appendix:architecture}{{A}{16}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces SimpleSmokingCNN Architecture Specification}}{16}{}\protected@file@percent }
\newlabel{tab:architecture}{{4}{16}{}{}{}}
\gdef \@abspage@last{16}
